{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "f, axis = plt.subplots(3,3)\n",
    "axis[0,0].imshow(digits.images[0])\n",
    "axis[0,1].imshow(digits.images[1])\n",
    "axis[0,2].imshow(digits.images[2])\n",
    "axis[1,0].imshow(digits.images[3])\n",
    "axis[1,1].imshow(digits.images[4])\n",
    "axis[1,2].imshow(digits.images[5])\n",
    "axis[2,0].imshow(digits.images[6])\n",
    "axis[2,1].imshow(digits.images[7])\n",
    "axis[2,2].imshow(digits.images[8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x173bb8109c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAALD0lEQVR4nO3dW4yU9RnH8d/PlYMgxLTahgAVjZYEGyuGYA2ptlAbrEZ70QtItKmx4aYaiU2M9q4X9dLoRWtCEGsi1bao0RiKGg+oSYtyaisuGEpUVpRDjAFtygo8vdghQbu678y8p336/SQbd3cm838m65d3dnbm/TsiBCCP05oeAEC5iBpIhqiBZIgaSIaogWROr+JGJ3pSTNbUKm66UfHNibWuN+m0Y7WtNbzzRG1roX//0ScajqMe7bJKop6sqbrMS6q46UYN/+7cWtebM+3D2tba950jta2F/m2K57/wMh5+A8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJFIra9lLbu2zvtn1n1UMB6N2YUdsekPRbSVdLmidpue15VQ8GoDdFjtQLJe2OiD0RMSzpUUnXVzsWgF4ViXqmpL2nfD3U+d5n2F5he7PtzZ/qaFnzAehSkahHe3vX/5ytMCJWRcSCiFgwQZP6nwxAT4pEPSRp9ilfz5K0r5pxAPSrSNSvS7rQ9nm2J0paJumpascC0KsxT5IQEcds3yLpGUkDktZExI7KJwPQk0JnPomI9ZLWVzwLgBLwijIgGaIGkiFqIBmiBpIhaiAZogaSIWogmUp26KjTwEVza1vrxYv+WNtatavxhb93H6rvZ7bx4jNqW6stOFIDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBMkR061tg+YPuNOgYC0J8iR+rfS1pa8RwASjJm1BHxsqQPa5gFQAlKe5eW7RWSVkjSZE0p62YBdKm0J8rYdgdoB579BpIhaiCZIn/SekTSXyXNtT1k++bqxwLQqyJ7aS2vYxAA5eDhN5AMUQPJEDWQDFEDyRA1kAxRA8kQNZDMuN9259Oz87555KZ3v1vbWq+9943a1vrNxU/WttZGXVDbWm3BkRpIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSKnKNstu0XbQ/a3mH7tjoGA9CbIq/9PibplxGx1fY0SVtsPxcRb1Y8G4AeFNl25/2I2Nr5/IikQUkzqx4MQG+6epeW7TmS5kvaNMplbLsDtEDhJ8psnynpMUkrI+Lw5y9n2x2gHQpFbXuCRoJeGxGPVzsSgH4Uefbbkh6QNBgR91Q/EoB+FDlSL5J0o6TFtrd3Pn5U8VwAelRk251XJbmGWQCUgFeUAckQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZDMuN9La8LO95oeoTL7rz+jtrUWPvlubWvNm7i/trXEXloAxjuiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiCZIicenGz7Ndt/72y78+s6BgPQmyIvEz0qaXFEfNw5VfCrtv8SEX+reDYAPShy4sGQ9HHnywmdj6hyKAC9K3oy/wHb2yUdkPRcRIy67Y7tzbY3f6qjZc8JoKBCUUfE8Yi4RNIsSQttf2uU67DtDtACXT37HREfSXpJ0tJKpgHQtyLPfp9j+6zO52dI+oGknVUPBqA3RZ79niHpIdsDGvlH4E8R8XS1YwHoVZFnv/+hkT2pAYwDvKIMSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWTG/bY7x/cfqG2tuw/NrW0tSVq/7dna1jpvw89rW+uuGRtqW2vgonp/Zsd37Kp1vdFwpAaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIJnCUXdO6L/NNicdBFqsmyP1bZIGqxoEQDmKbrszS9I1klZXOw6AfhU9Ut8r6Q5JJ77oCuylBbRDkR06rpV0ICK2fNn12EsLaIciR+pFkq6z/bakRyUttv1wpVMB6NmYUUfEXRExKyLmSFom6YWIuKHyyQD0hL9TA8l0dTqjiHhJI1vZAmgpjtRAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMo6I0m90ur8Sl3lJ6bf7/+bElfNrW+u0jdtqW+utNQtqW2vO7IO1rSVJE696p5Z1NsXzOhwferTLOFIDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBModMZdc4kekTScUnHIqK+1/kB6Eo35yj7fkQcqmwSAKXg4TeQTNGoQ9KztrfYXjHaFdh2B2iHog+/F0XEPttfk/Sc7Z0R8fKpV4iIVZJWSSNvvSx5TgAFFTpSR8S+zn8PSHpC0sIqhwLQuyIb5E21Pe3k55J+KOmNqgcD0JsiD7+/LukJ2yev/4eI2FDpVAB6NmbUEbFH0rdrmAVACfiTFpAMUQPJEDWQDFEDyRA1kAxRA8kQNZBMN2+9RM2yboXzzJL7alvr5pW317aWJE1UPdvufBmO1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJFMoattn2V5ne6ftQduXVz0YgN4Ufe33fZI2RMRPbE+UNKXCmQD0YcyobU+XdIWkn0lSRAxLGq52LAC9KvLw+3xJByU9aHub7dWd839/BtvuAO1QJOrTJV0q6f6ImC/pE0l3fv5KEbEqIhZExIIJmlTymACKKhL1kKShiNjU+XqdRiIH0EJjRh0RH0jaa3tu51tLJL1Z6VQAelb02e9bJa3tPPO9R9JN1Y0EoB+Foo6I7ZLqO98NgJ7xijIgGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkmEvrS7Uud+UJH1v3q7a1rpyyiu1rfWLn95S21pTNm4a+0rJcKQGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIZM2rbc21vP+XjsO2VdQwHoHtjvkw0InZJukSSbA9Iek/SExXPBaBH3T78XiLpXxHxThXDAOhft2/oWCbpkdEusL1C0gpJmsz+eUBjCh+pO+f8vk7Sn0e7nG13gHbo5uH31ZK2RsT+qoYB0L9uol6uL3joDaA9CkVte4qkqyQ9Xu04APpVdNudf0v6asWzACgBrygDkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBlHRPk3ah+U1O3bM8+WdKj0Ydoh633jfjXn3Ig4Z7QLKom6F7Y3R0S9m1XVJOt94361Ew+/gWSIGkimTVGvanqACmW9b9yvFmrN79QAytGmIzWAEhA1kEwrora91PYu27tt39n0PGWwPdv2i7YHbe+wfVvTM5XJ9oDtbbafbnqWMtk+y/Y62zs7P7vLm56pW43/Tt3ZIOAtjZwuaUjS65KWR8SbjQ7WJ9szJM2IiK22p0naIunH4/1+nWT7dkkLJE2PiGubnqcsth+S9EpErO6cQXdKRHzU9FzdaMOReqGk3RGxJyKGJT0q6fqGZ+pbRLwfEVs7nx+RNChpZrNTlcP2LEnXSFrd9Cxlsj1d0hWSHpCkiBgeb0FL7Yh6pqS9p3w9pCT/859ke46k+ZI2NTtJae6VdIekE00PUrLzJR2U9GDnV4vVtqc2PVS32hC1R/lemr+z2T5T0mOSVkbE4abn6ZftayUdiIgtTc9SgdMlXSrp/oiYL+kTSePuOZ42RD0kafYpX8+StK+hWUple4JGgl4bEVlOr7xI0nW239bIr0qLbT/c7EilGZI0FBEnH1Gt00jk40obon5d0oW2z+s8MbFM0lMNz9Q329bI72aDEXFP0/OUJSLuiohZETFHIz+rFyLihobHKkVEfCBpr+25nW8tkTTuntjsdoO80kXEMdu3SHpG0oCkNRGxo+GxyrBI0o2S/ml7e+d7v4qI9Q3OhLHdKmlt5wCzR9JNDc/Ttcb/pAWgXG14+A2gREQNJEPUQDJEDSRD1EAyRA0kQ9RAMv8FGDmh9o8PbacAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[9]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():     # Class for training and using a model for logistic regression\n",
    "    \n",
    "    \n",
    "    def set_values(self, initial_params, alpha=0.01, max_iter=5000, class_of_interest=0): \n",
    "        \n",
    "        #using self as it increases the readibility of the code\n",
    "        \n",
    "        #Setting the values \n",
    "        \n",
    "        self.params = initial_params                          # initial params\n",
    "        self.alpha = alpha                                    # step size \n",
    "        self.max_iter = max_iter                              # maximum iteration\n",
    "        self.class_of_interest = class_of_interest            #class of interest\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(x): #Sigmoid function block\n",
    "        \n",
    "        \n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def predict(self, x_bar, params): #predict the probability of a class\n",
    "        \n",
    "                \n",
    "        return self._sigmoid(np.dot(params, x_bar))\n",
    "    \n",
    "    def _compute_cost(self, input_var, output_var, params): #cost function block\n",
    "        \n",
    "        \n",
    "        cost = 0\n",
    "        for x, y in zip(input_var, output_var): #to map the similar index of two arrays\n",
    "            x_bar = np.array(np.insert(x, 0, 1))\n",
    "            y_hat = self.predict(x_bar, params)\n",
    "            \n",
    "            y_binary = 1.0 if y == self.class_of_interest else 0.0\n",
    "            cost += y_binary * np.log(y_hat) + (1.0 - y_binary) * np.log(1 - y_hat)\n",
    "            \n",
    "        return cost\n",
    "    \n",
    "    def train(self, input_var, label, print_iter = 5000):\n",
    "        \n",
    "        \n",
    "        iteration = 1\n",
    "        while iteration < self.max_iter:\n",
    "            if iteration % print_iter == 0:\n",
    "                print(f'iteration: {iteration}')\n",
    "                print(f'cost: {self._compute_cost(input_var, label, self.params)}')\n",
    "                print('--------------------------------------------')\n",
    "            \n",
    "            for i, xy in enumerate(zip(input_var, label)): \n",
    "                x_bar = np.array(np.insert(xy[0], 0, 1))\n",
    "                y_hat = self.predict(x_bar, self.params)\n",
    "                \n",
    "                y_binary = 1.0 if xy[1] == self.class_of_interest else 0.0\n",
    "                gradient = (y_binary - y_hat) * x_bar\n",
    "                self.params += self.alpha * gradient\n",
    "            \n",
    "            iteration +=1\n",
    "        \n",
    "        return self.params\n",
    "\n",
    "    def test(self, input_test, label_test):\n",
    "       # Testing the accuracy of the model using test data\n",
    "        self.total_classifications = 0\n",
    "        self.correct_classifications = 0\n",
    "        \n",
    "        for x,y in zip(input_test, label_test):\n",
    "            self.total_classifications += 1\n",
    "            x_bar = np.array(np.insert(x, 0, 1))\n",
    "            y_hat = self.predict(x_bar, self.params)\n",
    "            y_binary = 1.0 if y == self.class_of_interest else 0.0\n",
    "            \n",
    "            if y_hat >= 0.5 and  y_binary == 1:\n",
    "                # correct classification of class_of_interest\n",
    "                self.correct_classifications += 1\n",
    "              \n",
    "            if y_hat < 0.5 and  y_binary != 1:\n",
    "                # correct classification of an other class\n",
    "                self.correct_classifications += 1\n",
    "                \n",
    "        self.accuracy = self.correct_classifications / self.total_classifications\n",
    "            \n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data to training and test sets\n",
    "digits_train, digits_test, digits_label_train, digits_label_test =\\\n",
    "train_test_split(digits.data, digits.target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -1.6188049463746355\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -0.9102805371971725\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -0.6415281915982594\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -0.4978803206881576\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -0.4078857925150353\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -0.3459961330828373\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -0.3007257572193002\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -0.26612298649090405\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.23878687276922336\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the ZERO digit\n",
    "alpha = 1e-2\n",
    "params_0 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_0 = LogisticRegression()\n",
    "digits_regression_model_0.set_values(params_0, alpha, max_iter, 0)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_0.train(digits_train / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a ZERO digit in test set: 0.9944444444444445\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "digits_accuracy = digits_regression_model_0.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a ZERO digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -32.89496676952286\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -26.09004889771969\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -22.667628752915576\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -20.447631870618128\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -18.825950788084903\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -17.557090219576743\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -16.51915702899838\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -15.643523067240235\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -14.888026363848862\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the ONE digit\n",
    "alpha = 1e-2\n",
    "params_0 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_1 = LogisticRegression()\n",
    "digits_regression_model_1.set_values(params_0, alpha, max_iter, 1)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_1.train(digits_train / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a ONE digit in test set: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "digits_accuracy = digits_regression_\n",
    "model_1.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a ONE digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -2.9011462307044393\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -1.61598079729941\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -1.1365444730148377\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -0.881885193686448\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -0.7228150512110911\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -0.6135851851351486\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -0.5337448297073993\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -0.4727355090035416\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.4245389788036981\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the TWO digit\n",
    "alpha = 1e-2\n",
    "params_2 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_2 = LogisticRegression()\n",
    "digits_regression_model_2.set_values(params_2, alpha, max_iter, 2)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_2.train(digits_train / 16.0, digits_label_train, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediciting a TWO digit in test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_2.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a TWO digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -12.820339300327655\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -8.857864268866702\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -6.956523234870908\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -5.782692617766531\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -4.969072343457758\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -4.365541736898545\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -3.897354411557587\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -3.522337463202784\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -3.214577222876764\n",
      "--------------------------------------------\n",
      "Accuracy of prediciting a THREE digit in test set: 0.9527777777777777\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the THREE digit\n",
    "alpha = 1e-2\n",
    "params_3 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_3 = LogisticRegression()\n",
    "digits_regression_model_3.set_values(params_2, alpha, max_iter, 3)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_3.train(digits_train / 16.0, digits_label_train, 1000)\n",
    "\n",
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_3.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a THREE digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -4.564547558642502\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -2.6910855575868826\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -1.9420321048473457\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -1.5300756612585802\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -1.2670913149197198\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -1.0837262077883765\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -0.9481487809899838\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -0.8436075954927039\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.760412717743916\n",
      "--------------------------------------------\n",
      "Accuracy of prediciting a TWO digit in test set: 0.9972222222222222\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the FOUR digit\n",
    "alpha = 1e-2\n",
    "params_4 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_4 = LogisticRegression()\n",
    "digits_regression_model_4.set_values(params_4, alpha, max_iter, 4)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_4.train(digits_train / 16.0, digits_label_train, 1000)\n",
    "\n",
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_4.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a FOUR digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -9.74935852241987\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -6.121680421763806\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -4.535277608304822\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -3.6229599707744073\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -3.0245621157872553\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -2.599866446147323\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -2.282010577753134\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -2.0347948571776113\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -1.836819978411585\n",
      "--------------------------------------------\n",
      "Accuracy of prediciting a FIVE digit in test set: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the FIVE digit\n",
    "alpha = 1e-2\n",
    "params_5 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_5 = LogisticRegression()\n",
    "digits_regression_model_5.set_values(params_5, alpha, max_iter, 5)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_5.train(digits_train / 16.0, digits_label_train, 1000)\n",
    "\n",
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_5.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a FIVE digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -4.723904723413962\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -2.687361430417581\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -1.898351182055762\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -1.4737838261289233\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -1.2071070780629953\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -1.0235332374896777\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -0.8892200954524749\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -0.7865657495819326\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.7054898515176432\n",
      "--------------------------------------------\n",
      "Accuracy of prediciting a SIX digit in test set: 0.9972222222222222\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the SIX digit\n",
    "alpha = 1e-2\n",
    "params_6 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_6 = LogisticRegression()\n",
    "digits_regression_model_6.set_values(params_6, alpha, max_iter, 6)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_6.train(digits_train / 16.0, digits_label_train, 1000)\n",
    "\n",
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_6.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a SIX digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -5.87309143053808\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -3.4826499229563455\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -2.498574302390273\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -1.9547765456783937\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -1.6082902785733204\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -1.3676712816830208\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -1.1905741920962873\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -1.0546425943586801\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -0.9469397470471853\n",
      "--------------------------------------------\n",
      "Accuracy of prediciting a SEVEN digit in test set: 0.9944444444444445\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the SEVEN digit\n",
    "alpha = 1e-2\n",
    "params_7 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_7 = LogisticRegression()\n",
    "digits_regression_model_7.set_values(params_7, alpha, max_iter, 7)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_7.train(digits_train / 16.0, digits_label_train, 1000)\n",
    "\n",
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_7.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a SEVEN digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -103.3361824857824\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -100.93167566162265\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -100.22694004483888\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -99.92926479744887\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -99.7659600420248\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -99.6554035112111\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -99.56868403195826\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -99.49434334439944\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -99.42740582291476\n",
      "--------------------------------------------\n",
      "Accuracy of prediciting an EIGHT digit in test set: 0.9694444444444444\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the EIGHT digit\n",
    "alpha = 1e-2\n",
    "params_8 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_8 = LogisticRegression()\n",
    "digits_regression_model_8.set_values(params_8, alpha, max_iter, 8)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_8.train(digits_train / 16.0, digits_label_train, 1000)\n",
    "\n",
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_8.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting an EIGHT digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1000\n",
      "cost: -32.71405847816719\n",
      "--------------------------------------------\n",
      "iteration: 2000\n",
      "cost: -27.60132410640159\n",
      "--------------------------------------------\n",
      "iteration: 3000\n",
      "cost: -25.099211398392903\n",
      "--------------------------------------------\n",
      "iteration: 4000\n",
      "cost: -23.513731200840418\n",
      "--------------------------------------------\n",
      "iteration: 5000\n",
      "cost: -22.375697796083596\n",
      "--------------------------------------------\n",
      "iteration: 6000\n",
      "cost: -21.494252683755875\n",
      "--------------------------------------------\n",
      "iteration: 7000\n",
      "cost: -20.775800310550466\n",
      "--------------------------------------------\n",
      "iteration: 8000\n",
      "cost: -20.168753952206853\n",
      "--------------------------------------------\n",
      "iteration: 9000\n",
      "cost: -19.64220302498558\n",
      "--------------------------------------------\n",
      "Accuracy of prediciting a NINE digit in test set: 0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "# training a classifier for the NINE digit\n",
    "alpha = 1e-2\n",
    "params_9 = np.zeros(len(digits.data[0]) + 1)\n",
    "\n",
    "max_iter = 10000\n",
    "digits_regression_model_9 = LogisticRegression()\n",
    "digits_regression_model_9.set_values(params_9, alpha, max_iter, 9)\n",
    "\n",
    "params =\\\n",
    "digits_regression_model_9.train(digits_train / 16.0, digits_label_train, 1000)\n",
    "\n",
    "#accuracy\n",
    "digits_accuracy = digits_regression_model_9.test(digits_test / 16.0, digits_label_test)\n",
    "print(f'Accuracy of prediciting a NINE digit in test set: {digits_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
