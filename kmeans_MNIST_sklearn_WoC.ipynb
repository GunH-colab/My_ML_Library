{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing MNIST dataset into my notebook from keras' repository\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (60000, 28, 28)\n",
      "Training Labels: (60000,)\n"
     ]
    }
   ],
   "source": [
    "#viewing the dimensions of the data and target sets( of training set)\n",
    "\n",
    "print('Training Data: {}'.format(x_train.shape))\n",
    "print('Training Labels: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (10000, 28, 28)\n",
      "Training Labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#viewing the dimensions of the data and target sets( of testing set)\n",
    "\n",
    "print('Training Data: {}'.format(x_test.shape))\n",
    "print('Training Labels: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating figures with matplotlib.pyplot\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize = (5, 5))\n",
    "\n",
    "#looping through all the subplots and all the images from mnist dataset\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.matshow(x_train[100 + i])\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Number: {}'.format(y_train[100 + i]))\n",
    "    \n",
    "\n",
    "#displaying the figure \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each of the image into a one dimensional array\n",
    "\n",
    "X = x_train.reshape(len(x_train), -1)\n",
    "Y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] #viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(784,)\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# converting each of the image into a one dimensional array\n",
    "\n",
    "X = x_train.reshape(len(x_train), -1)\n",
    "Y = y_train\n",
    "\n",
    "# normalising the data from 0 to 1\n",
    "\n",
    "X = X.astype(float) / 255.\n",
    "\n",
    "print(X.shape)\n",
    "print(X[0].shape)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=100, compute_labels=True, init='k-means++',\n",
       "                init_size=None, max_iter=100, max_no_improvement=10,\n",
       "                n_clusters=10, n_init=3, random_state=None,\n",
       "                reassignment_ratio=0.01, tol=0.0, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans  # to implement kmeans using mini-batch\n",
    "\n",
    "n_digits = len(np.unique(y_test))\n",
    "print(n_digits)\n",
    "\n",
    "# Initializing KMeans model\n",
    "kmeans = MiniBatchKMeans(n_clusters = n_digits)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 8, 1, 3, 5, 0, 7, 4, 7, 2, 4, 3, 9, 6, 7, 2, 0, 3, 6, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    \n",
    "    #this function block associates the most probable label with each cluster in my kmeans model\n",
    "    #the function block also returns a list[dictionary actually] of clusters assigned to each label\n",
    "    \n",
    "\n",
    "    inferred_labels = {}  #stating dictionary in python\n",
    "\n",
    "    for i in range(kmeans.n_clusters):\n",
    "\n",
    "        # finding the index of points in cluster\n",
    "        \n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "\n",
    "        # appending or filling actual labels for each point in cluster\n",
    "        \n",
    "        labels.append(actual_labels[index])\n",
    "\n",
    "        # determining most common label\n",
    "        \n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0]) #bincount counts the number of elements\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "\n",
    "        # assigning the cluster to a value in the inferred_labels' dictionary\n",
    "        \n",
    "        if np.argmax(counts) in inferred_labels:  # appending the new number to the existing array at this slot\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else: # creatong a new array in this slot\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "\n",
    "    return inferred_labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_data_labels(X_labels, cluster_labels):\n",
    "    #this function block determines label for each array, depending on the cluster i has been assigned to.\n",
    "    #returns the predicted labels for each array or set\n",
    "    \n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)   # empty array of len(X)\n",
    "    \n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "                \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 0 4 1 7 2 1 8 1 7 8 1 3 6 1 7 2 1 6 7]\n",
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9]\n"
     ]
    }
   ],
   "source": [
    "# testing the two functions\n",
    "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
    "X_clusters = kmeans.predict(X)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "print(predicted_labels[:20])\n",
    "print(Y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics #to quantify the quality of predictions\n",
    "\n",
    "def calculate_metrics(estimator, data, labels):\n",
    "\n",
    "    # to Calculate and print metrics\n",
    "    print('Number of Clusters: {}'.format(estimator.n_clusters))\n",
    "    print('Inertia: {}'.format(estimator.inertia_))  #spread of the cluster ,,comparing performance \n",
    "    print('Homogeneity: {}'.format(metrics.homogeneity_score(labels, estimator.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters: 10\n",
      "Inertia: 2381651.0030149333\n",
      "Homogeneity: 0.45466893708406037\n",
      "Accuracy: 0.5558333333333333\n",
      "\n",
      "Number of Clusters: 16\n",
      "Inertia: 2198818.633779695\n",
      "Homogeneity: 0.5584902631781066\n",
      "Accuracy: 0.6540833333333333\n",
      "\n",
      "Number of Clusters: 36\n",
      "Inertia: 1960599.1532010902\n",
      "Homogeneity: 0.682688138700994\n",
      "Accuracy: 0.7595166666666666\n",
      "\n",
      "Number of Clusters: 64\n",
      "Inertia: 1808583.5255222307\n",
      "Homogeneity: 0.7378496763660919\n",
      "Accuracy: 0.82\n",
      "\n",
      "Number of Clusters: 144\n",
      "Inertia: 1633151.3997553806\n",
      "Homogeneity: 0.7982103844826957\n",
      "Accuracy: 0.8619666666666667\n",
      "\n",
      "Number of Clusters: 256\n",
      "Inertia: 1517417.442927316\n",
      "Homogeneity: 0.8420383996706925\n",
      "Accuracy: 0.8990166666666667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=400. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=400. Setting it to 3*k\n",
      "  init_size=init_size)\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:1561: RuntimeWarning: init_size=300 should be larger than k=400. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters: 400\n",
      "Inertia: 1434127.9400376012\n",
      "Homogeneity: 0.8591000115486865\n",
      "Accuracy: 0.9053166666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters = [10, 16, 36, 64, 144, 256, 400]\n",
    "\n",
    "# test different numbers of clusters\n",
    "for n_clusters in clusters:\n",
    "    estimator = MiniBatchKMeans(n_clusters = n_clusters)\n",
    "    estimator.fit(X)\n",
    "    \n",
    "    # printing cluster metrics\n",
    "    calculate_metrics(estimator, X, Y)\n",
    "    \n",
    "    # determining predicted labels\n",
    "    cluster_labels = infer_cluster_labels(estimator, Y)\n",
    "    predicted_Y = infer_data_labels(estimator.labels_, cluster_labels)\n",
    "    \n",
    "    # calculating and printing accuracy\n",
    "    print('Accuracy: {}\\n'.format(metrics.accuracy_score(Y, predicted_Y)))\n",
    "    \n",
    "    #Inertia is the sum of squared errors for each cluster.\n",
    "    #The smaller the inertia the denser the cluster.\n",
    "    #homogeneity means each cluster contains only members of a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing kmeans algorithm on testing dataset\n",
    "# converting each image to 1 dimensional array\n",
    "X_test = x_test.reshape(len(x_test),-1)\n",
    "\n",
    "# normalizing the data to 0 - 1\n",
    "X_test = X_test.astype(float) / 255.\n",
    "\n",
    "# initializing and fitting KMeans algorithm on training data\n",
    "kmeans = MiniBatchKMeans(n_clusters = 256)  #400 takes more time and does nothing better in accuracy \n",
    "kmeans.fit(X)\n",
    "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
    "\n",
    "# predicting labels for testing data\n",
    "test_clusters = kmeans.predict(X_test)\n",
    "predicted_labels = infer_data_labels(kmeans.predict(X_test), cluster_labels)\n",
    "    \n",
    "# calculating and printing accuracy\n",
    "print('Accuracy: {}\\n'.format(metrics.accuracy_score(y_test, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
